# Kafka 设计文档 中文翻译

## 1 动机

我们设计 Kafka 的初衷是希望它能处理大型公司实时数据的统一平台。为此我们想过了非常多的用户场景。

它需要高吞吐来支持大量的事件流例如实时的日志聚合。

它需要优雅地处理大量数据积压来支持离线系统周期性的数据加载。

同时它还需要具备低延迟的特性来应对传统的消息队列场景。

我们想要支持可分区，分布式的，实时处理新生成的消息，这促使了我们的分区和消费模型。

最终数据将会流向其他数据系统，该系统需要确保对硬件错误的容错。

对于上述场景的支持使我们的设计更加独特，比起传统的消息系统，kafka 更像是一个数据库。下面的章节我们会勾勒一些 kafka 的设计要素。

## 2 持久化

### 不要害怕文件系统!

Kafka 在缓存和存储消息上对文件系统有很强的依赖，现在外界总有一种声音说磁盘很慢，这让人们怀疑持久化设备是否能提供有竞争力的性能。事实上，磁盘可以比人们想象的快，也可以比人们想象的慢，这取决于如何使用。经过良好设计的磁盘结构和网络是一样快的。

磁盘性能的关键因素在于硬盘的吞吐在过去的十年里因为磁盘的 seek 操作而分化。在六块 7200rpm SATA RAID-5  的磁盘上的顺序写性能达到了600MB/s，但是随机写的性能只有 100k/s， 差了将近6000倍。顺序读写是所有的使用场景中是最常见的，并且被操作系统重度优化过。现代操作系统提供了 read ahead 和 write ahead 的技术，从大块数据中预先读取以及将小数据的写入转化成大数据的批量写入。实际上，对磁盘进行顺序访问比随机的内存访问更快。

现代操作系统为了缓解不同硬件上的性能分歧，非常激进地使用主存作为磁盘的缓存。现代的操作系统会非常乐意将所有的空闲内存用做磁盘的缓存，尽管在内存被重新分配时有一些小小的性能损失。所有的磁盘读写都会经过这道统一的缓存。如果不使用之间的IO操作，这个特性很难被关掉。所以如果一个进程中内存里保存了一份数据的缓存，这份数据大部分也可能在操作系统的页缓存上(pagecache)，成功地把所有东西存了两份。

不仅如此，Kafka 是基于 JVM 的系统，所有熟悉 Java 内存的人都知道两件事情：

1 对象的内存消耗非常高，经常是数据本身大小的两倍(或者更糟)

2 Java 的垃圾回收在堆数据增加时会更加缓慢。

因此使用文件系统并依赖页缓存比起维护内存缓存更合适。我们通过访问所有内存至少将可用的缓存数提高到两倍，通过存储压缩后的原始字节而非对象又可将可用缓存再提高两倍。在一台 32GB 的机器上可用的缓存可到达 28-30GB 并且没有受到GC的影响。甚至在服务重启时，缓存依然是有效的。然而在内存中的缓存则需要重新被加载(10GB的缓存需要加载10分钟)或者需要重新从所有缓存失效的情况开始。同时这也简化了代码，因为所有的保持内存和文件系统数据一致性的代码都在操作系统里了。并且更加有效。如果你的磁盘使用模式是顺序读取的，那么read ahead 将会在预计算缓存上非常有效。

这揭示了一个非常简单的设计：比起在维护尽可能多的内存然后在耗尽空间时把它落盘，我们更倾向于用持久化日志的方式直接顺序写到文件系统里，但不需要同步到磁盘上。这只是把数据转移到了内核的页缓存上。

这种以页缓存为中心的设计中这篇文章里有展开。

### 常数时间就够了

 消息队列里使用的持久化数据结构一般是每个队列采用一个对应一个 B 树或者其他利于随机读的数据结构。B树是最通用的数据结构，并且使消息系统能够支持事务型和非事务型的场景。尽管 B 树依然有较大的消耗：B 树的操作复杂度是 O(logN), 通常情况下，O(logN) 的复杂度被认为是常数时间，但是对于磁盘操作来说并不是如此。一次磁盘寻道操作需要10 ms，并且每个磁盘每次只能做一次磁盘寻道，所以也限制了并发。因此磁盘寻道也会有非常高的消耗。存储系统是非常快速的缓存操作和非常慢的磁盘操作的混合，在固定的缓存下，树结构的性能是随着数据量增长而超线性损失的。数据增长两倍会使之前的操作变慢超过两倍。

直觉上一个持久化队列可以通过顺序写文件来实现。这样的好处是所有的操作都是 O(1) 的，并且读写不会互相影响。这样的好处是性能完全和数据的大小解耦合了，一台服务器可以完全利用一块便宜的低转速的1TB SATA 硬盘。尽管它的寻道性能非常差，但是对于大量的读写操作可以做到 1/3 的价格换回3倍的容量。

## 3 效率




我们在性能上花了非常多力气。其中我们有一个主要场景是处理 web 的活跃数据，数据量非常大：每次访问一个页面都可能会产生数十次写操作。不仅如此，我们假设每条信息被至少一个消费者所用，所以我们努力使性能尽可能要好。

We have also found, from experience building and running a number of similar systems, that efficiency is a key to effective multi-tenant operations. If the downstream infrastructure service can easily become a bottleneck due to a small bump in usage by the application, such small changes will often create problems. By being very fast we help ensure that the application will tip-over under load before the infrastructure. This is particularly important when trying to run a centralized service that supports dozens or hundreds of applications on a centralized cluster as changes in usage patterns are a near-daily occurrence.

之前我们讨论了磁盘效率的问题，一旦糟糕的磁盘访问方式被限制之后，在这种类型的系统里只有两个会影响效率的因素：太多小型的 I/O 操作，以及过多的拷贝。

小的 I/O 操作在客户端，服务器端，服务器端持久化操作都会发生。

为了避免这样的操作，我们使用了一个 message set 的抽象将消息汇聚在一起。这使得网络请求把消息聚合在一起再发送过来，避免消息一条条地传输。服务端将消息一次性写进日志里，消费者也一次性读取多条消息。

这个小小的优化带来了巨大的速度提升，批处理导致了更大的网络包，更大的顺序磁盘操作，连续的内存块 等等，这一切使得 kafka 把随机的消息流转变为顺序写操作并流向消费者。

另一个性能的瓶颈在字节的拷贝上。在消息较少的情况下这不是一个问题，但是在负载较大的情况下就会有显著的影响。为了避免这样的消息拷贝，我们采用一套标准的二进制消息格式，通用于生产者，消费者，和服务端。

被服务端维护的消息日志只是文件夹里的一堆文件。通过维护统一的消息格式我们可以优化最重要的操作：通过网络传输日志文件。现代的 unix 操作系统提供了一套被优化的代码，用于将数据从页缓存中传输到套接字里，在 Linux 里使用 sendfile 这个系统调用来完成。

为了了解 sendfile 的影响，我们先来看一下正常情况下一个数据块是如何被传输到套接字上的：

1. 操作系统把磁盘上的数据读到内核空间中的页缓存里
2. 应用程序将内核空间中的数据读到用户空间中的 buffer 里
3. 应用程序将数据写回到内核空间中的套接字 buffer 里
4. 操作系统把数据从套接字 buffer 拷贝到 NIC buffer 里并传输给网络

这很明显不高效，

4 The Producer(生产者)

5 The Consumer(消费者)

6 消息传送原则/语义

7 数据冗余(Replica)

8 日志压缩(Log Compaction)

9 配额(Quota)
