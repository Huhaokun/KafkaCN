# Kafka 设计文档 中文翻译

## 1 动机

我们设计 Kafka 的初衷是希望它能处理大型公司实时数据的统一平台。为此我们想过了非常多的用户场景。

它需要高吞吐来支持大量的事件流例如实时的日志聚合。

它需要优雅地处理大量数据积压来支持离线系统周期性的数据加载。

同时它还需要具备低延迟的特性来应对传统的消息队列场景。

我们想要支持可分区，分布式的，实时处理新生成的消息，这促使了我们的分区和消费模型。

最终数据将会流向其他数据系统，该系统需要确保对硬件错误的容错。

对于上述场景的支持使我们的设计更加独特，比起传统的消息系统，kafka 更像是一个数据库。下面的章节我们会勾勒一些 kafka 的设计要素。

## 2 持久化

### 不要害怕文件系统!

Kafka 在缓存和存储消息上对文件系统有很强的依赖，现在外界总有一种声音说磁盘很慢，这让人们怀疑持久化设备是否能提供有竞争力的性能。事实上，磁盘可以比人们想象的快，也可以比人们想象的慢，这取决于如何使用。经过良好设计的磁盘结构和网络是一样快的。

磁盘性能的关键因素在于硬盘的吞吐在过去的十年里因为磁盘的 seek 操作而分化。在六块 7200rpm SATA RAID-5  的磁盘上的顺序写性能达到了600MB/s，但是随机写的性能只有 100k/s， 差了将近6000倍。顺序读写是所有的使用场景中是最常见的，并且被操作系统重度优化过。现代操作系统提供了 read ahead 和 write ahead 的技术，从大块数据中预先读取以及将小数据的写入转化成大数据的批量写入。实际上，对磁盘进行顺序访问比随机的内存访问更快。

现代操作系统为了缓解不同硬件上的性能分歧，非常激进地使用主存作为磁盘的缓存。现代的操作系统会非常乐意将所有的空闲内存用做磁盘的缓存，尽管在内存被重新分配时有一些小小的性能损失。所有的磁盘读写都会经过这道统一的缓存。如果不使用之间的IO操作，这个特性很难被关掉。所以如果一个进程中内存里保存了一份数据的缓存，这份数据大部分也可能在操作系统的页缓存上(pagecache)，成功地把所有东西存了两份。

不仅如此，Kafka 是基于 JVM 的系统，所有熟悉 Java 内存的人都知道两件事情：

1 对象的内存消耗非常高，经常是数据本身大小的两倍(或者更糟)

2 Java 的垃圾回收在堆数据增加时会更加缓慢。

因此使用文件系统并依赖页缓存比起维护内存缓存更合适。我们通过访问所有内存至少将可用的缓存数提高到两倍，通过存储压缩后的原始字节而非对象又可将可用缓存再提高两倍。在一台 32GB 的机器上可用的缓存可到达 28-30GB 并且没有受到GC的影响。甚至在服务重启时，缓存依然是有效的。然而在内存中的缓存则需要重新被加载(10GB的缓存需要加载10分钟)或者需要重新从所有缓存失效的情况开始。同时这也简化了代码，因为所有的保持内存和文件系统数据一致性的代码都在操作系统里了。并且更加有效。如果你的磁盘使用模式是顺序读取的，那么read ahead 将会在预计算缓存上非常有效。

这揭示了一个非常简单的设计：比起在维护尽可能多的内存然后在耗尽空间时把它落盘，我们更倾向于用持久化日志的方式直接顺序写到文件系统里，但不需要同步到磁盘上。这只是把数据转移到了内核的页缓存上。

这种以页缓存为中心的设计中这篇文章里有展开。

### 常数时间就够了

在消息队列系统里的持久数据结构经常使用每个消费者队列有一个对应的B树或者其他通用的随机访问数据结构来保存消息的元数据(metadata)。

## 3 效率




我们在性能上花了非常多力气。其中我们有一个主要场景是处理 web 的活跃数据，数据量非常大：每次访问一个页面都可能会产生数十次写操作。不仅如此，我们假设每条信息被至少一个消费者所用，所以我们努力使性能尽可能要好。
之前我们讨论了磁盘效率的问题，一旦糟糕的磁盘访问方式被限制之后，在这种类型的系统里只有两个会影响效率的因素：太多小型的 I/O 操作，以及过多的拷贝。

4 The Producer(生产者)

5 The Consumer(消费者)

6 消息传送原则/语义

7 数据冗余(Replica)

8 日志压缩(Log Compaction)

9 配额(Quota)
