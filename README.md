# Kafka 设计文档 中文翻译

## 1 动机

我们设计 Kafka 的初衷是希望它能处理大型公司实时数据的统一平台。为此我们想过了非常多的用户场景。

它需要高吞吐来支持大量的事件流例如实时的日志聚合。

它需要优雅地处理大量数据积压来支持离线系统周期性的数据加载。

同时它还需要具备低延迟的特性来应对传统的消息队列场景。

我们想要支持可分区，分布式的，实时处理新生成的消息，这促使了我们的分区和消费模型。

最终数据将会流向其他数据系统，该系统需要确保对硬件错误的容错。

对于上述场景的支持使我们的设计更加独特，比起传统的消息系统，kafka 更像是一个数据库。下面的章节我们会勾勒一些 kafka 的设计要素。

## 2 持久化

**不要害怕文件系统!**

Kafka 在缓存和存储消息上对文件系统有很强的依赖，现在外界总有一种声音说磁盘很慢，这让人们怀疑持久化设备是否能提供有竞争力的性能。事实上，磁盘可以比人们想象的快，也可以比人们想象的慢，这取决于如何使用。经过良好设计的磁盘结构和网络是一样快的。

磁盘性能的关键因素在于硬盘的吞吐在过去的十年里因为磁盘的 seek 操作而分化。在六块 7200rpm SATA RAID-5  的磁盘上的顺序写性能达到了600MB/s，但是随机写的性能只有 100k/s， 差了将近6000倍。顺序读写是所有的使用场景中是最常见的，并且被操作系统重度优化过。现代操作系统提供了 read ahead 和 write ahead 的技术，从大块数据中预先读取以及将小数据的写入转化成大数据的批量写入。实际上，对磁盘进行顺序访问比随机的内存访问更快。

现代操作系统为了缓解不同硬件上的性能分歧，非常激进地使用主存作为磁盘的缓存。现代的操作系统会非常乐意将所有的空闲内存用做磁盘的缓存，尽管在内存被重新分配时有一些小小的性能损失。所有的磁盘读写都会经过这道统一的缓存。如果不使用之间的IO操作，这个特性很难被关掉。所以如果一个进程中内存里保存了一份数据的缓存，这份数据大部分也可能在操作系统的页缓存上(pagecache)，成功地把所有东西存了两份。

不仅如此，Kafka 是基于 JVM 的系统，所有熟悉 Java 内存的人都知道两件事情：

1 对象的内存消耗非常高，经常是数据本身大小的两倍(或者更糟)

2 Java 的垃圾回收在堆数据增加时会更加缓慢。

因此使用文件系统并依赖页缓存比起维护内存缓存更合适。我们通过访问所有内存至少将可用的缓存数提高到两倍，通过存储压缩后的原始字节而非对象又可将可用缓存再提高两倍。在一台 32GB 的机器上可用的缓存可到达 28-30GB 并且没有受到GC的影响。甚至在服务重启时，缓存依然是有效的。然而在内存中的缓存则需要重新被加载(10GB的缓存需要加载10分钟)或者需要重新从所有缓存失效的情况开始。同时这也简化了代码，因为所有的

## 3 效率



4 The Producer(生产者)

5 The Consumer(消费者)

6 消息传送原则/语义

7 数据冗余(Replica)

8 日志压缩(Log Compaction)

9 配额(Quota)