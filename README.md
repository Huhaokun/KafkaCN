# Kafka 设计文档 中文翻译

## 1 动机

我们设计 Kafka 的初衷是希望它能处理大型公司实时数据的统一平台。为此我们想过了非常多的用户场景。

它需要高吞吐来支持大量的事件流例如实时的日志聚合。

它需要优雅地处理大量数据积压来支持离线系统周期性的数据加载。

同时它还需要具备低延迟的特性来应对传统的消息队列场景。

我们想要支持可分区，分布式的，实时处理新生成的消息，这促使了我们的分区和消费模型。

最终数据将会流向其他数据系统，该系统需要确保对硬件错误的容错。

对于上述场景的支持使我们的设计更加独特，比起传统的消息系统，kafka 更像是一个数据库。下面的章节我们会勾勒一些 kafka 的设计要素。

## 2 持久化

### 不要害怕文件系统!

Kafka 在缓存和存储消息上对文件系统有很强的依赖，现在外界总有一种声音说磁盘很慢，这让人们怀疑持久化设备是否能提供有竞争力的性能。事实上，磁盘可以比人们想象的快，也可以比人们想象的慢，这取决于如何使用。经过良好设计的磁盘结构和网络是一样快的。

磁盘性能的关键因素在于硬盘的吞吐在过去的十年里因为磁盘的 seek 操作而分化。在六块 7200rpm SATA RAID-5  的磁盘上的顺序写性能达到了600MB/s，但是随机写的性能只有 100k/s， 差了将近6000倍。顺序读写是所有的使用场景中是最常见的，并且被操作系统重度优化过。现代操作系统提供了 read ahead 和 write ahead 的技术，从大块数据中预先读取以及将小数据的写入转化成大数据的批量写入。实际上，对磁盘进行顺序访问比随机的内存访问更快。

现代操作系统为了缓解不同硬件上的性能分歧，非常激进地使用主存作为磁盘的缓存。现代的操作系统会非常乐意将所有的空闲内存用做磁盘的缓存，尽管在内存被重新分配时有一些小小的性能损失。所有的磁盘读写都会经过这道统一的缓存。如果不使用之间的IO操作，这个特性很难被关掉。所以如果一个进程中内存里保存了一份数据的缓存，这份数据大部分也可能在操作系统的页缓存上(pagecache)，成功地把所有东西存了两份。

不仅如此，Kafka 是基于 JVM 的系统，所有熟悉 Java 内存的人都知道两件事情：

1 对象的内存消耗非常高，经常是数据本身大小的两倍(或者更糟)

2 Java 的垃圾回收在堆数据增加时会更加缓慢。

因此使用文件系统并依赖页缓存比起维护内存缓存更合适。我们通过访问所有内存至少将可用的缓存数提高到两倍，通过存储压缩后的原始字节而非对象又可将可用缓存再提高两倍。在一台 32GB 的机器上可用的缓存可到达 28-30GB 并且没有受到GC的影响。甚至在服务重启时，缓存依然是有效的。然而在内存中的缓存则需要重新被加载(10GB的缓存需要加载10分钟)或者需要重新从所有缓存失效的情况开始。同时这也简化了代码，因为所有的保持内存和文件系统数据一致性的代码都在操作系统里了。并且更加有效。如果你的磁盘使用模式是顺序读取的，那么read ahead 将会在预计算缓存上非常有效。

这揭示了一个非常简单的设计：比起在维护尽可能多的内存然后在耗尽空间时把它落盘，我们更倾向于用持久化日志的方式直接顺序写到文件系统里，但不需要同步到磁盘上。这只是把数据转移到了内核的页缓存上。

这种以页缓存为中心的设计中这篇文章里有展开。

### 常数时间就够了

 消息队列里使用的持久化数据结构一般是每个队列采用一个对应一个 B 树或者其他利于随机读的数据结构。B树是最通用的数据结构，并且使消息系统能够支持事务型和非事务型的场景。尽管 B 树依然有较大的消耗：B 树的操作复杂度是 O(logN), 通常情况下，O(logN) 的复杂度被认为是常数时间，但是对于磁盘操作来说并不是如此。一次磁盘寻道操作需要10 ms，并且每个磁盘每次只能做一次磁盘寻道，所以也限制了并发。因此磁盘寻道也会有非常高的消耗。存储系统是非常快速的缓存操作和非常慢的磁盘操作的混合，在固定的缓存下，树结构的性能是随着数据量增长而超线性损失的。数据增长两倍会使之前的操作变慢超过两倍。

直觉上一个持久化队列可以通过顺序写文件来实现。这样的好处是所有的操作都是 O(1) 的，并且读写不会互相影响。这样的好处是性能完全和数据的大小解耦合了，一台服务器可以完全利用一块便宜的低转速的1TB SATA 硬盘。尽管它的寻道性能非常差，但是对于大量的读写操作可以做到 1/3 的价格换回3倍的容量。

## 3 效率




我们在性能上花了非常多力气。其中我们有一个主要场景是处理 web 的活跃数据，数据量非常大：每次访问一个页面都可能会产生数十次写操作。不仅如此，我们假设每条信息被至少一个消费者所用，所以我们努力使性能尽可能要好。

We have also found, from experience building and running a number of similar systems, that efficiency is a key to effective multi-tenant operations. If the downstream infrastructure service can easily become a bottleneck due to a small bump in usage by the application, such small changes will often create problems. By being very fast we help ensure that the application will tip-over under load before the infrastructure. This is particularly important when trying to run a centralized service that supports dozens or hundreds of applications on a centralized cluster as changes in usage patterns are a near-daily occurrence.

之前我们讨论了磁盘效率的问题，一旦糟糕的磁盘访问方式被限制之后，在这种类型的系统里只有两个会影响效率的因素：太多小型的 I/O 操作，以及过多的拷贝。

小的 I/O 操作在客户端，服务器端，服务器端持久化操作都会发生。

为了避免这样的操作，我们使用了一个 message set 的抽象将消息汇聚在一起。这使得网络请求把消息聚合在一起再发送过来，避免消息一条条地传输。服务端将消息一次性写进日志里，消费者也一次性读取多条消息。

这个小小的优化带来了巨大的速度提升，批处理导致了更大的网络包，更大的顺序磁盘操作，连续的内存块 等等，这一切使得 kafka 把随机的消息流转变为顺序写操作并流向消费者。

另一个性能的瓶颈在字节的拷贝上。在消息较少的情况下这不是一个问题，但是在负载较大的情况下就会有显著的影响。为了避免这样的消息拷贝，我们采用一套标准的二进制消息格式，通用于生产者，消费者，和服务端。

被服务端维护的消息日志只是文件夹里的一堆文件。通过维护统一的消息格式我们可以优化最重要的操作：通过网络传输日志文件。现代的 unix 操作系统提供了一套被优化的代码，用于将数据从页缓存中传输到套接字里，在 Linux 里使用 sendfile 这个系统调用来完成。

为了了解 sendfile 的影响，我们先来看一下正常情况下一个数据块是如何被传输到套接字上的：

1. 操作系统把磁盘上的数据读到内核空间中的页缓存里
2. 应用程序将内核空间中的数据读到用户空间中的 buffer 里
3. 应用程序将数据写回到内核空间中的套接字 buffer 里
4. 操作系统把数据从套接字 buffer 拷贝到 NIC buffer 里并传输给网络

这很明显不高效，这里总共有4次拷贝和两次系统调用。使用 sendfile，让操作系统从页缓存直接传输数据到网络上。在这条优化后的路径上，只有一次拷贝。

在一个topic上有多个消费者，使用上述的 zero-copy 优化，数据被拷贝到页缓存上恰好一次，并且可以被重用而不是每次要读取数据时从页缓存上拷贝到用户的 buffer 上。这样消费数据的速度几乎可以达到网络传输的极限。

### 端到端的批压缩

在某些场景下瓶颈在于网络带宽而不是 CPU 或者磁盘。对于需要跨数据中心进行数据传输的场景下非常常见。当然，用户可以自己把数据进行压缩而不需要 kafka 的支持。但是这样的压缩率并不是很高，因为很多数据的冗余都来自同样类型的消息（比如 JSON 的字段名，或者日志中公共的字符串）。高效的压缩需要同时压缩多条消息而不是对单条消息进行压缩。

Kafka 使用了批处理的格式来支持批压缩消息。一个批次的信息能够被一起进行压缩，并在传输过程中保持被压缩，直到消费者这边才被解压。

Kafka 支持 GZIP，Snappy，LZ4 压缩协议。

##  4 The Producer(生产者)

### 负载均衡

生产者直接把数据发送到 当前分区到 leader broker 上。为了能让生产者知道哪个节点是 leader，所有的 Kafka 节点提供一个接口用于告诉生产者哪台机器是活着的，哪台机器是选举出的 leader，这样生产者能直接把请求发给正确的机器。

客户端来控制它发送到哪个分区上。可以由随机的算法来完成，也可以是带某些语义的分区策略。我们暴露了分区的接口让用户可以自定义分区的 key 。同时也暴露了分区的函数。举个例子，如果一个 key 是用户的 id，那么同一个用户的所有数据都会被分配到同一个分区上。这样用户可以对他们的数据有个具体的假设。这种分区的策略是为了满足用户在对数据存放敏感性。

### 异步发送

批量处理是提高效率的一个巨大改动，为了达到批处理，kafka 生产者会把数据攒到内存里放入单个请求中。批处理的策略可以倍配置为不超过某个固定数字，或者不超过某个固定的时间。这样可以使发送的字节数更多，在服务器上有更少的 IO 操作。buffer 的大小是可配置的，让用户牺牲一些实时性，但是获得更大的吞吐。

## 5 The Consumer(消费者)

Kafka 消费者通过向某个分区的 leading broker 发送拉取请求来获取数据。消费者指定日志的偏移量，接受从该偏移量起始的一块日志。这样消费者就可以控制拉取的位置，并且可以回放，重新消费数据。

### 推 vs 拉

一个初始的问题是，消费者应该从 broker 拉数据还是应该由 broker 向消费者推数据。 Kafka 采用了更加传统的设计，数据推向 broker，消费者从 broker 拉数据。某些日志中心的系统，比如 scribe 和 flume，采用非常不同的推数据的方式。两种方式各有利弊，但是一个基于推的系统处理多种消费者会有难度，因为推送数据的频率是由 broker 控制的。通常情况下希望消费者能够以最大负载取消费数据，但是在推的系统里这意味着消费者在出现问题时，消费数据的速度跟不上生产的速度，将会导致消费者被请求淹没。在拉的系统里，落后的消费者只需要保证在恢复自己的消费能力之后赶上当前的进度即可。当消费者发现自己已经过载时，通过控制 kafka 的拉取，也可以缓解自身的压力。

拉系统的另一个好处是客户端可以自己聚合数据调用批处理接口。一个推系统必须决定要么立刻发送要么攒一波数据再发，它无法知道下游的消费者能否立刻处理它。一个拉系统能够解决这个问题，因为消费者永远只拉它可消费的数据。

拉系统的一个缺点是如果 broker当前没有数据，那么消费者困在一直在循环里空转，等待数据的到达。为了避免不必要的等待，在拉数据的请求里设置一个参数，可以让该请求一直阻塞住直到数据到达。



6 消息传送原则/语义

7 数据冗余(Replica)

8 日志压缩(Log Compaction)

9 配额(Quota)
